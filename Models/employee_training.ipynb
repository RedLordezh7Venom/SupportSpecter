{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N21RdOrLM-C",
        "outputId": "3320f7a5-4593-45f9-b670-533237957ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.134)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "E8xTC2-EMFZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os"
      ],
      "metadata": {
        "id": "_EMqpcwiMFcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf"
      ],
      "metadata": {
        "id": "GYdS9xWtMFfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "import langchain_google_genai\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "AT0IO1rmMFho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "3v3HBqjOMFkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "s3Y-oqEgMFm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "GOiRS7umMFps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "OjTr_7nnMFsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "oWRy8IMcMFvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def querie_generator(sector, field, experience):\n",
        "    prompt = (\n",
        "        \"Pretend that you are a senior in the customer service sector of a large company in {sector}. \"\n",
        "        \"You are tasked with training new employees to become familiar with customer issues. \"\n",
        "        \"Consider their field of expertise: {field}, and their experience level: {experience}. \"\n",
        "        \"Generate one realistic customer complaint situation for the employee to tackle. \"\n",
        "        \"Ensure the situation reflects different sentiments without explicitly stating them, allowing the employee to identify the emotions involved. \"\n",
        "        \"Do not include tips or additional information.\"\n",
        "    )\n",
        "\n",
        "    # Insert the field and experience into the prompt\n",
        "    formatted_prompt = prompt.format(sector=sector, field=field, experience=experience)\n",
        "\n",
        "    # Create a message object for the LLM\n",
        "    message = HumanMessage(content=formatted_prompt)\n",
        "\n",
        "    # Get the response from the LLM\n",
        "    response = llm.invoke([message])\n",
        "\n",
        "    # Extract and clean the generated text\n",
        "    generated_text = response.content.strip()\n",
        "\n",
        "    # Return the generated situation directly\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "mTUnUF9pMF0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "querie_generator(\"ed-tech\",\"software\", \"fresher\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ezxL4shIMF3W",
        "outputId": "2196a10e-7c81-4e8d-bf63-fc5d485f8082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**Situation:**\\n\\nA customer, a school principal, calls to report an issue with the recently implemented online learning software. They explain that the software frequently crashes during online classes, disrupting instruction and frustrating students. The customer's tone is initially calm but becomes increasingly frustrated as they describe the impact on their school.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def response_evaluation(query, employee_response):\n",
        "    \"\"\"\n",
        "    Evaluates the employee's response against a generated customer complaint situation.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): The customer complaint situation generated by the querie_generator function.\n",
        "    - employee_response (str): The response provided by the employee to the complaint.\n",
        "\n",
        "    Returns:\n",
        "    - A dictionary with scores and detailed feedback for each evaluation criterion.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    prompt = (\n",
        "        f\"Evaluate the following employee response for handling a customer complaint:\\n\\n\"\n",
        "        f\"Customer Complaint: '{query}'\\n\\n\"\n",
        "        f\"Employee Response: '{employee_response}'\\n\\n\"\n",
        "        \"Assess the response based on the following criteria:\\n\"\n",
        "        \"1. Correct Identification of the Customer's Issue\\n\"\n",
        "        \"2. Quality of Proposed Solution\\n\"\n",
        "        \"3. Likelihood of Customer Satisfaction\\n\"\n",
        "        \"4. Adherence to Company Policy\\n\"\n",
        "        \"Provide a score (out of 100) and detailed feedback for each criterion.\"\n",
        "        \"also provide the best response to the query which u think will be the best evaluating the sentiments and everything\"\n",
        "    )\n",
        "\n",
        "\n",
        "    message = HumanMessage(content=prompt)\n",
        "\n",
        "\n",
        "    response = llm.invoke([message])\n",
        "\n",
        "\n",
        "    evaluation_results = response.content.strip()\n",
        "\n",
        "\n",
        "    return evaluation_results"
      ],
      "metadata": {
        "id": "Ajt0IyoaMF59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = querie_generator(\"retail\",\"electronics\", \"experienced\")\n",
        "employee_response = \"I understand your frustration with the laptop issue. I will escalate this to our technical team and ensure it gets resolved quickly.\"\n",
        "evaluation_results = response_evaluation(query, employee_response)\n",
        "print(evaluation_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI02CU82MF8w",
        "outputId": "ad8fe5c6-c9de-4be8-cfb9-6dd5a4b58f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**1. Correct Identification of the Customer's Issue**\n",
            "\n",
            "* Score: 100\n",
            "* Feedback: The employee correctly identified the customer's issues with the battery life and screen flickering.\n",
            "\n",
            "**2. Quality of Proposed Solution**\n",
            "\n",
            "* Score: 80\n",
            "* Feedback: The employee's proposed solution of escalating the issue to the technical team is appropriate. However, it would be more effective if the employee provided a specific timeline for resolution or offered alternative options, such as a replacement laptop or a refund.\n",
            "\n",
            "**3. Likelihood of Customer Satisfaction**\n",
            "\n",
            "* Score: 70\n",
            "* Feedback: While the employee acknowledged the customer's frustration, the response lacked empathy and did not provide any reassurance or apology. Additionally, the lack of a clear resolution timeline could lead to further frustration for the customer.\n",
            "\n",
            "**4. Adherence to Company Policy**\n",
            "\n",
            "* Score: 100\n",
            "* Feedback: The employee's response did not violate any company policies, as it acknowledged the customer's complaint and offered to escalate it.\n",
            "\n",
            "**Best Response**\n",
            "\n",
            "\"I sincerely apologize for the issues you've been experiencing with your laptop. I understand how frustrating this can be, especially when you're relying on it for both personal and professional use. I will immediately escalate this to our technical team and ensure they investigate the problem thoroughly. In the meantime, I can offer you a replacement laptop so that you can continue working without interruption. We value your business and want to make sure that you're completely satisfied with your purchase. Please let me know if you have any further questions or concerns.\"\n",
            "\n",
            "This response addresses all of the criteria effectively:\n",
            "\n",
            "* **Correct Identification of Issue:** Acknowledges the customer's specific issues.\n",
            "* **Quality of Solution:** Offers a clear solution (replacement laptop) and a specific action (escalation to technical team).\n",
            "* **Likelihood of Satisfaction:** Apologizes, expresses empathy, and provides reassurance.\n",
            "* **Adherence to Policy:** Follows company protocol for handling customer complaints.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gtREwApjMF_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MNVUWG4nMGCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABsN4H8rMGFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}